{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq2uUJd4vasb"
      },
      "source": [
        "![](https://raw.githubusercontent.com/batistagroup/ChemSpaceAL/packaging/media/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIXuCJuWvxPr"
      },
      "source": [
        "This Colab notebook allows you to easily implement [ChemSpaceAL v2.0.0](https://github.com/batistagroup/ChemSpaceAL/). For more details, check out the associated [preprint on arXiv](https://arxiv.org/abs/2309.05853). Please feel free to start any discussion or raise any issues on our [GitHub](https://github.com/batistagroup/ChemSpaceAL/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM4RkGcWvPnO"
      },
      "source": [
        "![](https://raw.githubusercontent.com/batistagroup/ChemSpaceAL/packaging/media/toc_figure.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "ZaOS8lmivRyk"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title Set Up Notebook (Cell 1)\n",
        "#@markdown Press the *Play* button to install ChemSpaceAL and its dependencies\n",
        "\n",
        "!rm -r ChemSpaceAL\n",
        "!git clone --single-branch --branch main https://github.com/batistagroup/ChemSpaceAL\n",
        "!git clone https://github.com/Liuhong99/Sophia.git\n",
        "!pip install ChemSpaceAL/.\n",
        "\n",
        "import ChemSpaceAL\n",
        "from ChemSpaceAL import InitializeWorkspace\n",
        "from ChemSpaceAL import Configuration\n",
        "from ChemSpaceAL import Dataset\n",
        "from ChemSpaceAL import Model\n",
        "from ChemSpaceAL import Training\n",
        "from ChemSpaceAL import Generation\n",
        "from ChemSpaceAL import Sampling\n",
        "from ChemSpaceAL import ALConstruction\n",
        "base_path = None\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFYfz0Fjw_Qr"
      },
      "source": [
        "# Initialize the Workspace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlBHtsxExBg4"
      },
      "source": [
        "As implemented in the paper, one iteration of ChemSpaceAL takes ~22 hours, of which 20 are spent on docking. To ensure no data is lost due to accidental termination of Colab sessions, we strongly recommend connecting Google Drive and creating a dedicated folder for storing results of runs.\n",
        "\n",
        "If you do not execute the cell below, all files will be saved within local sessions and will be lost if the session terminates!\n",
        "\n",
        "Please note that this package has been optimized for running multiple AL iterations. Practically, this means that the code may seem daunting to you at first, but once you get familiar with it, you can analyze the results of scoring from some AL iteration and launch the docking for the next iteration within 30 min! Feel free [to reach out to us](https://github.com/batistagroup/ChemSpaceAL/) if you need help with getting started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrO0vcmN5tJl",
        "outputId": "a7e06364-c9a1-4359-fa70-b5970c22f245"
      },
      "outputs": [],
      "source": [
        "# @title Specify (base) path for storing results (Cell 2)\n",
        "# @markdown make sure your path ends with a \"/\"\n",
        "from google.colab import drive\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/ChemSpaceAL-runs/\"  # @param {type:\"string\"}\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKLEfaEG8Mg-"
      },
      "source": [
        "## Create subfolders for storing results\n",
        "By default, the following folder structure will be created\n",
        "\n",
        "```\n",
        "ChemSpaceAL-runs\n",
        "├── 1_Pretraining\n",
        "│   ├── dataset_folder: datasets\n",
        "│   ├── desc_folder: datasets_descriptors\n",
        "│   └── weight_folder: model_weights\n",
        "├── 2_Generation\n",
        "├── 3_Sampling\n",
        "│   ├── desc_folder: generations_descriptors\n",
        "│   ├── pca_folder: pca_weights\n",
        "│   ├── kmeans_folder: kmeans_objects\n",
        "│   └── clustering_folder: clusterings\n",
        "├── 4_Scoring\n",
        "│   ├── target_folder: binding_targets\n",
        "│   ├── candidate_folder: sampled_mols\n",
        "│   ├── pose_folder: binding_poses\n",
        "│   └── score_folder: scored_dataframes\n",
        "└── 5_ActiveLearning\n",
        "    ├── train_folder: training_sets\n",
        "    ├── desc_folder: trainingset_descriptors\n",
        "    └── weight_folder: model_weights\n",
        "```\n",
        "\n",
        "This structure is specified by `InitializeWorkspace.FOLDER_STRUCTURE`. The values to keys `*_folder` are the folder names. You're more than welcome them to rename if you want and pass a new folder_structure dict to `InitializeWorkspace.create_folders` as an optional parameter `folder_structure=`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm3jRgP-w0SX",
        "outputId": "0dfaa0c2-0528-4202-f6eb-b09c85425993"
      },
      "outputs": [],
      "source": [
        "# @title create subfolders (Cell 3)\n",
        "# @markdown By default, the following folder structure will be created\n",
        "if base_path is None:\n",
        "    base_path = os.getcwd() + \"/runs/\"\n",
        "InitializeWorkspace.create_folders(base_path=base_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vVlLnpXxzAM",
        "outputId": "e4c615a1-52b0-4873-b9e5-5cd6f457583f"
      },
      "outputs": [],
      "source": [
        "# @title Download (if you want) dataset/weights (Cell 4)\n",
        "# @markdown note these files will be placed into appropriate folders created above\n",
        "downloadDataset = True  # @param {type:\"boolean\"}\n",
        "downloadModelWeights = True  # @param {type:\"boolean\"}\n",
        "downloadPCAweights = True  # @param {type:\"boolean\"}\n",
        "downloadTargets = True  # @param {type:\"boolean\"}\n",
        "script = \"\"\"#!/bin/bash\n",
        "\"\"\"\n",
        "remote_source = \"https://files.ischemist.com/ChemSpaceAL/publication_runs/\"\n",
        "if downloadDataset:\n",
        "    f1 = \"1_Pretraining/datasets/combined_train.csv.gz\"\n",
        "    f2 = \"1_Pretraining/datasets/combined_valid.csv.gz\"\n",
        "    script += f\"curl -o {base_path}{f1} {remote_source}{f1}\\n\"\n",
        "    script += f\"curl -o {base_path}{f2} {remote_source}{f2}\\n\"\n",
        "if downloadModelWeights:\n",
        "    f1 = \"1_Pretraining/datasets_descriptors/combined_train.yaml\"\n",
        "    f2 = \"1_Pretraining/model_weights/model7_al0_ch1.pt\"\n",
        "    script += f\"curl -o {base_path}{f1} {remote_source}{f1}\\n\"\n",
        "    script += f\"curl -o {base_path}{f2} {remote_source}{f2}\\n\"\n",
        "if downloadPCAweights:\n",
        "    f1 = \"3_Sampling/pca_weights/scaler_pca_combined_n120_v2.pkl\"\n",
        "    script += f\"curl -o {base_path}{f1} {remote_source}{f1}\\n\"\n",
        "if downloadTargets:\n",
        "    f1 = \"4_Scoring/binding_targets/HNH_processed.pdb\"\n",
        "    f2 = \"4_Scoring/binding_targets/1iep_processed.pdb\"\n",
        "    script += f\"curl -o {base_path}{f1} {remote_source}{f1}\\n\"\n",
        "    script += f\"curl -o {base_path}{f2} {remote_source}{f2}\\n\"\n",
        "with open(\"fetch.bash\", \"w\") as f:\n",
        "    f.write(script)\n",
        "!bash fetch.bash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm1l1QtQ9C_a"
      },
      "source": [
        "# Active Learning Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aRfJ-qr9gV3"
      },
      "source": [
        "First, we have to initialize a global config. A brief explanation of some of the parameters.\n",
        "\n",
        "`cycle_prefix`, `al_iteration`, and `cycle_suffix` are used to compose filenames for all results and intermediary output. For example, with default parameters, all filenames will start as `model0_al0_ch1`. We recommend changing `cycle_prefix` for different pretrained generative models, changing `cycle_suffix` for different settings of AL, and you **must** not forget to increment `al_iteration` as you progress through AL cycles.\n",
        "\n",
        "`training_fname` and `validation_fname`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f0s_Wxe372P"
      },
      "source": [
        "## Setting parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTtBaQrK9Uyt",
        "outputId": "b58d7fa7-25d9-465c-fef0-ed7f8a24e87d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- The following previously scored molecules were set:\n",
            "     4_Scoring/scored_dataframes/model0_al0_ch1.csv\n",
            "--- The following previously constructed Active Learning sets were set:\n",
            "     5_ActiveLearning/training_sets/model0_al0_ch1.csv\n"
          ]
        }
      ],
      "source": [
        "# Cell 5\n",
        "config = Configuration.Config(\n",
        "    base_path=base_path,\n",
        "    cycle_prefix=\"model0\",\n",
        "    cycle_suffix=\"ch1\",\n",
        "    al_iteration=0,  # use 0 for pretraining\n",
        "    training_fname=\"combined_train.csv.gz\",\n",
        "    validation_fname=\"combined_valid.csv.gz\",\n",
        "    slice_data=None,\n",
        "    verbose=True,  # will print every important decision that's going to be made\n",
        ")\n",
        "# The following fills two lists (or you could provide them manually as optional parameters)\n",
        "# `previously_scored_mols` - a list of strings of paths to previously scored molecules\n",
        "# `previous_al_train_sets` - a list of strings of paths to AL training sets from previous iterations\n",
        "# these lists are needed to\n",
        "# - assess how many of generated molecules are repeated from AL training sets\n",
        "# - make sure already scored molecules are not sampled again for docking\n",
        "# notably, if you do not mess with the default naming system, these lists will be filled for you automatically\n",
        "# once you change al_iteration to a non-zero value!\n",
        "config.set_previous_arrays()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90FvuJD03_ZD"
      },
      "source": [
        "## Pretraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyXNSHq2zxcj",
        "outputId": "f3a17b38-e30e-46af-ef4d-495f00387d46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- The following training parameters were set:\n",
            "    number of epochs: 10\n",
            "    learning rate: 0.0003\n",
            "    learning warmup enabled? True\n",
            "    model weights will be saved to:               1_Pretraining/model_weights/model0_al1_ch1.pt                                   \n",
            "    dataset descriptors will be loaded from:      1_Pretraining/datasets_descriptors/combined_train.yaml                          \n",
            "  . note: wandb_project_name and wandb_runname were not provided, you can ignore this message if you don't plan to log runs to wandb\n"
          ]
        }
      ],
      "source": [
        "# Cell 6\n",
        "# You can also overwrite `learning_rate`, `lr_warmup` (a boolean of whether to do lr warmup),\n",
        "# For a full list of available parameters run help(config.set_training_parameters)\n",
        "config.set_training_parameters(mode=\"Pretraining\", epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gizQ7Vow-1Nd"
      },
      "outputs": [],
      "source": [
        "# Cell 7\n",
        "# mode can be set to \"Pretraining\" or \"Active Learning\".\n",
        "# In \"Pretraining\", an output is a list of two dataset objects corrresponding to (train, valid) partitions\n",
        "# In \"Active Learning\", an output is a single dataset object corresponding to an AL training set\n",
        "datasets = Dataset.load_data(config=config, mode=\"Pretraining\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytrX5o7Z0qJ3",
        "outputId": "e8b1e0be-6729-46e1-8956-ea8e07ff5649"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 1 iter 0: train loss 3.00065. lr 2.938127e-04: 100%|██████████| 1/1 [00:00<00:00,  6.44it/s]\n",
            "epoch 2 iter 0: train loss 2.44265. lr 2.733530e-04: 100%|██████████| 1/1 [00:00<00:00,  5.42it/s]\n",
            "epoch 3 iter 0: train loss 2.61905. lr 2.405980e-04: 100%|██████████| 1/1 [00:00<00:00,  7.27it/s]\n",
            "epoch 4 iter 0: train loss 2.36641. lr 1.988125e-04: 100%|██████████| 1/1 [00:00<00:00,  6.43it/s]\n",
            "epoch 5 iter 0: train loss 2.31899. lr 1.521616e-04: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]\n",
            "epoch 6 iter 0: train loss 2.32882. lr 1.052952e-04: 100%|██████████| 1/1 [00:00<00:00,  7.29it/s]\n",
            "epoch 7 iter 0: train loss 2.30736. lr 6.288478e-05: 100%|██████████| 1/1 [00:00<00:00,  7.55it/s]\n",
            "epoch 8 iter 0: train loss 2.30499. lr 3.000000e-05: 100%|██████████| 1/1 [00:00<00:00,  7.54it/s]\n",
            "epoch 9 iter 0: train loss 2.29886. lr 3.000000e-05: 100%|██████████| 1/1 [00:00<00:00,  7.41it/s]\n",
            "epoch 10 iter 0: train loss 2.29016. lr 3.000000e-05: 100%|██████████| 1/1 [00:00<00:00,  7.64it/s]\n"
          ]
        }
      ],
      "source": [
        "# Cell 8\n",
        "# model objects and trainer objects are returned in case you want to do something with them\n",
        "model, trainer = Training.train_GPT(\n",
        "    config=config, training_dataset=datasets[0], validation_dataset=datasets[1]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vnwS1RZ4BOO"
      },
      "source": [
        "## Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSB3TfwA10t5",
        "outputId": "3aa6ee29-61fc-4e07-8937-96628a0a3b95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- The following generation parameters were set:\n",
            "    target number: 1 unique canonical smiles that pass filters\n",
            "    batch size: 64 & temperature: 1.0\n",
            "    the following filters will be applied: ADMET+FGs\n",
            "    model weights will be loaded from:            1_Pretraining/model_weights/model0_al1_ch1.pt                                   \n",
            "    dataset descriptors will be loaded from:      1_Pretraining/datasets_descriptors/combined_train.yaml                          \n",
            "    generated completions will be saved to:       2_Generation/model0_al1_ch1_completions.csv                                     \n",
            "    unique canonic smiles will be saved to:       2_Generation/model0_al1_ch1_unique_smiles.csv                                   \n",
            "    generation metrics will be saved to:          2_Generation/model0_al1_ch1_metrics.txt                                         \n",
            "    filtered molecules will be saved to:          2_Generation/model0_al1_ch1_filtered_smiles.csv                                 \n",
            "    The following ADMET filters will be enforced:\n",
            "    |    MW in range [100, 600]\n",
            "    |    nHA in range [0, 12]\n",
            "    |    nHD in range [0, 7]\n",
            "    |    nRot in range [0, 11]\n",
            "    |    nRing in range [0, 6]\n",
            "    |    nHet in range [1, 15]\n",
            "    |    fChar in range [-4, 4]\n",
            "    |    TPSA in range [0, 140]\n",
            "    |    logP in range [-0.4, 6.5]\n",
            "    The following functional groups will be restricted:\n",
            "    |    fr_azide, fr_isocyan, fr_isothiocyan, fr_nitro, fr_nitro_arom,\n",
            "    |    fr_nitro_arom_nonortho, fr_nitroso, fr_phos_acid, fr_phos_ester,\n",
            "    |    fr_sulfonamd, fr_sulfone, fr_term_acetylene, fr_thiocyan,\n",
            "    |    fr_prisulfonamd, fr_C_S, fr_azo, fr_diazo, fr_epoxide, fr_ester,\n",
            "    |    fr_COO2, fr_Imine, fr_N_O, fr_SH, fr_aldehyde, fr_dihydropyridine,\n",
            "    |    fr_hdrzine, fr_hdrzone, fr_ketone, fr_thiophene, fr_phenol\n"
          ]
        }
      ],
      "source": [
        "# Cell 9\n",
        "config.set_generation_parameters(\n",
        "    target_criterion=\"force_number_filtered\", # or you could choose `force_number_unique` or `force_number_completions`\n",
        "    force_filters=\"ADMET+FGs\", # could choose `ADMET` for no restriction on functional groups or simply remove this parameter\n",
        "    target_number=100_000,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g1fCwHI3pUN"
      },
      "outputs": [],
      "source": [
        "# Cell 10\n",
        "Generation.generate_smiles(config) # this runs generation of SMILES\n",
        "Generation.characterize_generated_molecules(config) # this runs an analysis of # unique, valid, and novel molecules"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QKvwE3T5SnV"
      },
      "source": [
        "## Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDp1SaQB5TBX",
        "outputId": "47f67014-093c-42b4-bd0e-0ce6342016cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- The following sampling parameters were set:\n",
            "    number of clusters: 10\n",
            "    samples per cluster: 2\n",
            "    descriptors mode: mix\n",
            "    descriptors will be saved to:                      3_Sampling/generations_descriptors/model0_al1_ch1.pkl                           \n",
            "    PCA will be loaded from:                           3_Sampling/pca_weights/scaler_pca_combined_n120.pkl                             \n",
            "    KMeans Objects will be saved to:                   3_Sampling/kmeans_objects/model0_al1_ch1_k10.pkl                                \n",
            "    cluster to molecules mapping will be saved to:     3_Sampling/clusterings/model0_al1_ch1_cluster_to_mols.pkl                       \n",
            "    sampled molecules will be saved to:                4_Scoring/sampled_mols/model0_al1_ch1_sampled20.csv                             \n"
          ]
        }
      ],
      "source": [
        "# Cell 11\n",
        "config.set_sampling_parameters(\n",
        "    n_clusters=10,\n",
        "    samples_per_cluster=2,\n",
        "    pca_fname=\"scaler_pca_combined_n120_v2.pkl\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdqp-6Li6PfT"
      },
      "outputs": [],
      "source": [
        "# Cell 12\n",
        "Sampling.calculate_descriptors(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 13\n",
        "mols = Sampling.project_into_pca_space(config)\n",
        "# n_iter below specifies how many times K-Means is run with different starting points\n",
        "Sampling.cluster_and_sample(mols=mols, config=config, n_iter=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCe3_uK5TXr"
      },
      "source": [
        "## Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "bjes5o_e6v_2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#@title Install Docking Software (DiffDock) (Cell 14)\n",
        "#@markdown diffdock is pretty heavy and has a lot of dependencies, so we only install it when we need it (and we don't during pretraining, for example)\n",
        "import torch\n",
        "\n",
        "print(torch.__version__)\n",
        "\n",
        "try:\n",
        "    import torch_geometric\n",
        "except ModuleNotFoundError:\n",
        "    !pip uninstall torch-scatter torch-sparse torch-geometric torch-cluster  --y\n",
        "    !pip install torch-scatter -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install torch-cluster -f https://data.pyg.org/whl/torch-{torch.__version__}.html --quiet\n",
        "    !pip install git+https://github.com/pyg-team/pytorch_geometric.git  --quiet \n",
        "\n",
        "try:\n",
        "    import biopandas\n",
        "except:\n",
        "    !pip install pyg==0.7.1 --quiet\n",
        "    !pip install pyyaml==6.0 --quiet\n",
        "    !pip install scipy==1.7.3 --quiet\n",
        "    !pip install networkx==2.6.3 --quiet\n",
        "    !pip install biopython==1.79 --quiet\n",
        "    !pip install e3nn==0.5.0 --quiet\n",
        "    !pip install spyrmsd==0.5.2 --quiet\n",
        "    !pip install pandas==1.5.3 --quiet\n",
        "    !pip install biopandas==0.4.1 --quiet\n",
        "\n",
        "if not os.path.exists(\"/content/DiffDock\"):\n",
        "    os.chdir('/content')\n",
        "    !git clone https://github.com/gcorso/DiffDock.git\n",
        "    os.chdir('/content/DiffDock')\n",
        "    !git checkout a6c5275\n",
        "    os.chdir('/content')\n",
        "\n",
        "if not os.path.exists(\"/content/DiffDock/esm\"):\n",
        "    os.chdir('/content/DiffDock')\n",
        "    !git clone https://github.com/facebookresearch/esm\n",
        "    os.chdir('/content/DiffDock/esm')\n",
        "    !git checkout ca8a710\n",
        "    !sudo pip install -e .\n",
        "    os.chdir('/content/DiffDock')\n",
        "    os.chdir('/content')\n",
        "\n",
        "from rdkit import Chem\n",
        "import shutil\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_top_poses(ligands_csv: str, protein_pdb_path: str, save_pose_path: str):\n",
        "    data = pd.read_csv(ligands_csv)\n",
        "    os.makedirs(save_pose_path, exist_ok=True)\n",
        "\n",
        "    os.environ['HOME'] = 'esm/model_weights'\n",
        "    os.environ['PYTHONPATH'] = f'{os.environ.get(\"PYTHONPATH\", \"\")}:/content/DiffDock/esm'\n",
        "    pbar = tqdm(range(len(data)), total=len(data))\n",
        "    for i in pbar:  # change 1 to len(data) for processing all ligands\n",
        "        # print(str((i / len(data)) * 100)[:5], ' %')\n",
        "        smiles = data['smiles'][i]\n",
        "        rdkit_mol = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "        if rdkit_mol is not None:\n",
        "            with open('/content/input_protein_ligand.csv', 'w') as out:\n",
        "                out.write('protein_path,ligand\\n')\n",
        "                out.write(f'{protein_pdb_path},{smiles}\\n')\n",
        "\n",
        "            # Clear out old results if running multiple times\n",
        "            shutil.rmtree('/content/DiffDock/results', ignore_errors=True)\n",
        "\n",
        "            # ESM Embedding Preparation\n",
        "            os.chdir('/content/DiffDock')\n",
        "            !python /content/DiffDock/datasets/esm_embedding_preparation.py --protein_ligand_csv /content/input_protein_ligand.csv --out_file /content/DiffDock/data/prepared_for_esm.fasta\n",
        "\n",
        "            # ESM Extraction\n",
        "            !python /content/DiffDock/esm/scripts/extract.py esm2_t33_650M_UR50D /content/DiffDock/data/prepared_for_esm.fasta /content/DiffDock/data/esm2_output --repr_layers 33 --include per_tok --truncation_seq_length 30000\n",
        "\n",
        "            # Inference\n",
        "            !python /content/DiffDock/inference.py --protein_ligand_csv /content/input_protein_ligand.csv --out_dir /content/DiffDock/results/user_predictions_small --inference_steps 20 --samples_per_complex 10 --batch_size 6\n",
        "\n",
        "            # Move results\n",
        "            for root, dirs, files in os.walk('/content/DiffDock/results/user_predictions_small'):\n",
        "                for file in files:\n",
        "                    if file.startswith('rank1_confidence'):\n",
        "                        shutil.move(\n",
        "                            os.path.join(root, file),\n",
        "                            os.path.join(save_pose_path, f\"complex{i}.sdf\"),\n",
        "                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj43Lidy9MWx",
        "outputId": "8503eafc-eab0-47a9-a0e7-2121b59d9f50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- The following scoring parameters were set:\n",
            "    Reminder that docking poses will be written to 4_Scoring/binding_poses/                                                        \n",
            "    protein will be loaded from                   4_Scoring/binding_targets/HNH_processed.pdb                                     \n",
            "    poses will be saved to                        4_Scoring/binding_poses/model0_al1_ch1/                                         \n",
            "    and scored molecules will be saved to         4_Scoring/scored_dataframes/model0_al1_ch1.csv                                  \n",
            "    The following prolif interaction weights will be used:\n",
            "    |    Hydrophobic: 2.5, HBDonor: 3.5, HBAcceptor: 3.5, Anionic: 7.5, Cationic: 7.5,\n",
            "    |    CationPi: 2.5, PiCation: 2.5, VdWContact: 1.0, XBAcceptor: 3.0,\n",
            "    |    XBDonor: 3.0, FaceToFace: 3.0, EdgeToFace: 1.0, MetalDonor: 3.0,\n",
            "    |    MetalAcceptor: 3.0\n"
          ]
        }
      ],
      "source": [
        "# Cell 15\n",
        "config.set_scoring_parameters(\n",
        "    protein_path=\"HNH_processed.pdb\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GChMeujNDErG"
      },
      "source": [
        "### Docking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AAW56ri8-LZ",
        "outputId": "817f3521-3d17-4329-de1d-a3929bdcd15f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 1515.06it/s]\n"
          ]
        }
      ],
      "source": [
        "# Cell 16\n",
        "get_top_poses(\n",
        "    ligands_csv=config.cycle_temp_params[\"path_to_sampled\"],\n",
        "    protein_pdb_path=config.cycle_temp_params[\"path_to_protein\"],\n",
        "    save_pose_path=config.cycle_temp_params[\"path_to_poses\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj6fJycjDIzk"
      },
      "source": [
        "### Counting attractive interaction scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_CatI-oDD-T",
        "outputId": "4b386f98-898b-41e8-e095-7aaefdbcdd02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21/21 [00:07<00:00,  2.94it/s]\n"
          ]
        }
      ],
      "source": [
        "# Cell 17\n",
        "from ChemSpaceAL import Scoring\n",
        "ligand_scores = Scoring.score_ligands(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8DBlUedBC5i"
      },
      "outputs": [],
      "source": [
        "# Cell 18\n",
        "Scoring.parse_and_prepare_diffdock_data(\n",
        "    ligand_scores=ligand_scores,\n",
        "    config=config\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bTKgdFB5U1r"
      },
      "source": [
        "## Active Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNnNENATEYeX",
        "outputId": "d395ac8e-a970-469e-eb09-90dd71ab3331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- The following AL training set construction parameters were set:\n",
            "    the training set will be constructed to have 10 molecules\n",
            "    of which 5 will be selected from the top scoring molecules defined by the following parameters:\n",
            "        molecules with score above 11 will be selected\n",
            "    the remaining 5 molecules will be selected from high-scoring clusters according to the following parameters:\n",
            "        the following probability mode will be used: linear\n",
            "    the training set will be saved to             5_ActiveLearning/training_sets/model0_al1_ch1.csv                               \n"
          ]
        }
      ],
      "source": [
        "# Cell 19\n",
        "config.set_active_learning_parameters(\n",
        "    selection_mode=\"threshold\", probability_mode=\"linear\", threshold=11, training_size=10_000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j6MiofeEOzk"
      },
      "outputs": [],
      "source": [
        "# Cell 20\n",
        "ALConstruction.construct_al_training_set(config=config, do_sampling=True)\n",
        "ALConstruction.translate_dataset_for_al(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbkAwpOzGK61",
        "outputId": "7e5f0804-8be2-42d5-9952-19ca3a33ab4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Will load AL training set from 5_ActiveLearning/training_sets/model0_al0_ch1.csv\n"
          ]
        }
      ],
      "source": [
        "# Cell 21\n",
        "al_ds = Dataset.load_data(config=config, mode=\"Active Learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iphPbepYHYIr",
        "outputId": "fd1ff31d-3f40-4245-8101-15c11a86cae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- The following training parameters were set:\n",
            "    number of epochs: 1\n",
            "    learning rate: 3e-05\n",
            "    learning warmup enabled? False\n",
            "    model weights will be loaded from:            1_Pretraining/model_weights/model0_al0_ch1.pt                                   \n",
            "    model weights will be saved to:               5_ActiveLearning/model_weights/model0_al1_ch1.pt                                \n",
            "    dataset descriptors will be loaded from:      1_Pretraining/datasets_descriptors/combined_train.yaml                          \n",
            "  . note: wandb_project_name and wandb_runname were not provided, you can ignore this message if you don't plan to log runs to wandb\n"
          ]
        }
      ],
      "source": [
        "# Cell 22\n",
        "config.set_training_parameters(mode=\"Active Learning\", epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KePj2bHZ37wR"
      },
      "outputs": [],
      "source": [
        "# Cell 23\n",
        "model, trainer = Training.train_GPT(\n",
        "    config=config,\n",
        "    training_dataset=al_ds,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
